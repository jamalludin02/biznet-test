services:
  # PHP Backend - Barcode Generator
  php-generator-barcode:
    build:
      context: ./php
      dockerfile: Dockerfile
    ports:
      - "8080:80"
    networks:
      - biznet-network
    restart: unless-stopped

  # Frontend - Vue.js AI Knowledge Chat
  ai-knowledge-frontend:
    build:
      context: ./ai-knowledge
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - VITE_OLLAMA_URL=http://localhost:11434
    depends_on:
      - ollama
    networks:
      - biznet-network
    restart: unless-stopped

  # Ollama Service with Gemma3:1b model
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./entrypoint.sh:/entrypoint.sh
    environment:
      - OLLAMA_HOST=0.0.0.0
    networks:
      - biznet-network
    restart: unless-stopped
    entrypoint: ["/bin/bash", "/entrypoint.sh"]

  # Nginx Reverse Proxy (Optional)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - ai-knowledge-frontend
    networks:
      - biznet-network
    restart: unless-stopped

volumes:
  ollama_data:

networks:
  biznet-network:
    driver: bridge